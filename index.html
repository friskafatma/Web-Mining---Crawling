



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>Crawling Website - My Docs</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/application.982221ab.css">
      
      
    
    
      <script src="assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#penambangan-dan-pencarian-web" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="." title="My Docs" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              My Docs
            </span>
            <span class="md-header-nav__topic">
              Crawling Website
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="." title="My Docs" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    My Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1" checked>
    
    <label class="md-nav__link" for="nav-1">
      Crawling Text Website
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        Crawling Text Website
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Crawling Website
      </label>
    
    <a href="." title="Crawling Website" class="md-nav__link md-nav__link--active">
      Crawling Website
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#penambangan-dan-pencarian-web" title="PENAMBANGAN DAN PENCARIAN WEB" class="md-nav__link">
    PENAMBANGAN DAN PENCARIAN WEB
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#definisi" title="DEFINISI" class="md-nav__link">
    DEFINISI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tujuan" title="TUJUAN" class="md-nav__link">
    TUJUAN
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crawling" title="CRAWLING" class="md-nav__link">
    CRAWLING
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pre-processing" title="Pre-processing" class="md-nav__link">
    Pre-processing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matriks-vsm" title="MATRIKS VSM" class="md-nav__link">
    MATRIKS VSM
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf" title="TF-IDF" class="md-nav__link">
    TF-IDF
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seleksi-fitur" title="SELEKSI FITUR" class="md-nav__link">
    SELEKSI FITUR
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clustering" title="CLUSTERING" class="md-nav__link">
    CLUSTERING
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kesimpulan" title="KESIMPULAN" class="md-nav__link">
    KESIMPULAN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Crawling Structure Website
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Crawling Structure Website
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="webstruc/" title="Crawling Website Structure" class="md-nav__link">
      Crawling Website Structure
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#penambangan-dan-pencarian-web" title="PENAMBANGAN DAN PENCARIAN WEB" class="md-nav__link">
    PENAMBANGAN DAN PENCARIAN WEB
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#definisi" title="DEFINISI" class="md-nav__link">
    DEFINISI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tujuan" title="TUJUAN" class="md-nav__link">
    TUJUAN
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crawling" title="CRAWLING" class="md-nav__link">
    CRAWLING
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pre-processing" title="Pre-processing" class="md-nav__link">
    Pre-processing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matriks-vsm" title="MATRIKS VSM" class="md-nav__link">
    MATRIKS VSM
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf" title="TF-IDF" class="md-nav__link">
    TF-IDF
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seleksi-fitur" title="SELEKSI FITUR" class="md-nav__link">
    SELEKSI FITUR
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clustering" title="CLUSTERING" class="md-nav__link">
    CLUSTERING
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kesimpulan" title="KESIMPULAN" class="md-nav__link">
    KESIMPULAN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Crawling Website</h1>
                
                <h3 id="penambangan-dan-pencarian-web">PENAMBANGAN DAN PENCARIAN WEB</h3>
<p>Friska Fatmawatiningrum (160411100084)</p>
<p>Target website : https://thegorbalsla.com/category/pendidikan/</p>
<p>Program yang dibutuhkan : Python 3.6 (dengan library requests, beautifulsoup4, sqlite3, csv, numpy, scikit-learn, sastrawi, scikit-fuzzy)</p>
<h4 id="definisi">DEFINISI</h4>
<p>Web crawler merupakan suatu alat atau program yang digunakan search engine untuk meng index atau menjelajahi seluruh web yang ada di internet.</p>
<h4 id="tujuan">TUJUAN</h4>
<p>Tujuan utamanya adalah mengumpulkan data atau informasi dari sebuah halaman web. contohnya yaitu search engine sehingga ketika pengguna Internet mengetikkan kata pencarian di komputernya, search engine dapat dengan segera menampilkan web site yang relevan.</p>
<p>Dan pada tugas ini saya melakukan crawling untuk mengambil data kemudian akan mengelompokkan data yang sudah di crawling menggunakan metode clustering.</p>
<p><strong>Langkah - langkah :</strong></p>
<h4 id="crawling">CRAWLING</h4>
<p>dIgunakan untuk mengambil data dari sebuah website, baik berupa text, citra, audio, video, dll. Dan kali ini akan mengambil data berupa text saja. Dengan meng-import library BeautifulSoup4 terlebih dahulu </p>
<pre><code>from bs4 import BeautifulSoup
</code></pre>

<p>Code program :</p>
<pre><code>   conn = sqlite3.connect('articles.sqlite')
   conn.execute('DROP TABLE if exists articles')
   conn.execute('''CREATE TABLE ARTICLES
                   (TITLE         TEXT     NOT NULL,
                    ISI         TEXT     NOT NULL);''')
   conn.commit()
   src = &quot;https://thegorbalsla.com/category/pendidikan/&quot;

   n = 1
   while n &lt;= 15:
       print(n)
       page = requests.get(src)
       soup = BeautifulSoup(page.content, 'html.parser')

       linkhead = soup.findAll(class_='read-more')
       nextpage = soup.find(class_='next page-numbers')

       for links in linkhead:
           try :
               src = links['href']
               page = requests.get(src)
               soup = BeautifulSoup(page.content, 'html.parser')

               konten = soup.find('article')
               title = konten.find(class_='entry-title').getText()
               temp = konten.findAll('p')

               isi = []
               for j in range(len(temp)):
                   isi += [temp[j].getText()]

               isif = &quot;&quot;
               for i in isi:
                   isif += i
               conn.execute(&quot;INSERT INTO ARTICLES (TITLE, ISI) VALUES (?, ?)&quot;, (title, isif));

           except AttributeError:
               continue
       conn.commit()
       src = nextpage['href']
       n+=1
</code></pre>

<p>Terlebih dahulu dibuat database nya dengan sqlite3  dan diconnect kan dengan sqlite, database bernama articles, dengan tabel articles yang mempunyai atribut title dan isi.</p>
<pre><code>   conn = sqlite3.connect('articles.sqlite')
   conn.execute('DROP TABLE if exists articles')
   conn.execute('''CREATE TABLE ARTICLES
                   (TITLE         TEXT     NOT NULL,
                    ISI         TEXT     NOT NULL);''')
   conn.commit()
</code></pre>

<p>kemudian link website yang di crawl disimpan di variable src </p>
<pre><code>   src = &quot;https://thegorbalsla.com/category/pendidikan/&quot;
</code></pre>

<p>perulangan dengan kondisi while dilakukan sebanyak 15 kali, karena saya melakukan crawling next page sebanyak 15 halaman dengan masing masing halaman berisi 3 artikel.</p>
<pre><code>   linkhead = soup.findAll(class_='read-more')
   nextpage = soup.find(class_='next page-numbers')
</code></pre>

<p>Menggunakan fungsi soup.find dan soup.findAll yang ada pada BeautifulSoup4 untuk mengambil data dari class yang diketahui saat inspect elemen html. variabel linkhead untuk masuk ke isi artikel dan variabel nextpage untuk masuk ke link page selanjutnya.</p>
<pre><code>   konten = soup.find('article')
   title = konten.find(class_='entry-title').getText()
   temp = konten.findAll('p')
</code></pre>

<p>Code diatas digunakan untuk mengcrawling isi dari artikel tersebut yang berada pada satu class bernama article, dan judul dimuat pada class yang ada di variabel title kemudian diambil textnya dengan getText(), sedangkan untuk setial kalimat isinya di muat dalam tag html <p> yang ada pada variable temp.</p>
<p>kemudian terdapat perulangan untuk mengambil semua paragraf pada isi artikel setelah itu di insert kan ke dalam database yang sudah dibuat.</p>
<h4 id="pre-processing">Pre-processing</h4>
<p>tahap ini dilakukan dengan beberapa tahapan :</p>
<ol>
<li>Stopword Removal, untuk menghilangkan kata yang tidak penting.</li>
<li>Stemming, untuk mengubah suata kata yang berimbuhan menjadi kata dasar.</li>
<li>Tokenisasi (n-gram), untuk memecah kalimat menjadi per-kata.</li>
</ol>
<p>Berikut Code programnya dengan menggunakan library Sastrawi :</p>
<pre><code>   cursor = conn.execute(&quot;SELECT* from ARTICLES&quot;)
   factory = StopWordRemoverFactory()
   stopword = factory.create_stop_word_remover()
   from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
   factory = StemmerFactory()
   stemmer = factory.create_stemmer()
   stop = stopword.remove(isif)
   stem = stemmer.stem(stop)
   katadasar = stem.split()
</code></pre>

<p>Mengambil dari tabel articles di database kemudian dilakukan stopword, lalu stemming dan tokenisasi dengan fungsi split.</p>
<pre><code>   matrix=[]
   for row in cursor:
       tampung = []
       for i in katadasar:
           tampung.append(row[1].lower().count(i))
       matrix.append(tampung)
</code></pre>

<p>Kode diatas digunakan untuk memasukkan hasil preprocessing dalam matrix</p>
<pre><code>   def write_csv(nama_file, isi, tipe='w'):
       'tipe=w; write; tipe=a; append;'
       with open(nama_file, mode=tipe) as tbl:
           tbl_writer = csv.writer(tbl, delimiter=',', quotechar='&quot;', quoting=csv.QUOTE_MINIMAL)
           for row in isi:
               tbl_writer.writerow(row)

   write_csv(&quot;kata_before_11_16.csv&quot;, katadasar)
</code></pre>

<p>Function diatas digunakan untuk otomatis membuat dan membaca data csv dengan parameter nama_file, isi, dan tipe='w'. Kemudian disimpan di file csv kata_before_11_16.csv.</p>
<p>Agar kata dasar yang diambil beraturan maka kita deteksi yang sesuai dengan KBBI dan untuk itu kita membutuhkan database kata dari KBBI yang tersimpan di file database KBI.db.</p>
<pre><code>   conn = sqlite3.connect('KBI.db')
   cur_kbi = conn.execute(&quot;SELECT* from KATA&quot;)

   def LinearSearch (kbi,kata):
       found=False
       posisi=0
       while posisi &lt; len (kata) and not found :
           if kata[posisi]==kbi:
               found=True
           posisi=posisi+1
       return found

   berhasil=[]
   berhasil2=''
   for kata in cur_kbi :
       ketemu=LinearSearch(kata[0],katadasar)
       if ketemu :
           kata = kata[0]
           berhasil.append(kata)
           berhasil2=berhasil2+' '+kata
   print(berhasil)
</code></pre>

<p>code diatas digunakan untuk mendeteksi katadasar yang sudah ditemukan pada proses preprocessing dicek kata dasarnya bersarkan KBBI dengan melihat di tabal KATA pada KBI.db.</p>
<h4 id="matriks-vsm">MATRIKS VSM</h4>
<p>merupakan proses perhitungan kemunculan semua kata yang terdapat pada setiap dokumen.</p>
<pre><code>   conn = sqlite3.connect('articles.sqlite')
   matrix2=[]
   cursor = conn.execute(&quot;SELECT* from ARTICLES&quot;)
   for row in cursor:
       tampung = []
       for i in berhasil:
           tampung.append(row[1].lower().count(i))
       matrix2.append(tampung)
   print(matrix2)

   write_csv(&quot;kata_after_11_16.csv&quot;, berhasil)
</code></pre>

<p>code diatas digunakan untuk menghitung banyaknya kemunculan seluruh kata yang ada pada setiap dokumen yang di crawling untuk proses deteksi ini membutuhkan waktu yang lama karena jumlahbkata yang banyak. Setelah itu prosesnya disimpan ke dalam file kata_after_11_16.csv yang telah mengalami pengecekan kata dasar sesuai KBBI.</p>
<h4 id="tf-idf">TF-IDF</h4>
<p>kependekan dari Term Frequence (Frekuensi kata) dan Invers Document Frequence (invers frekuensi dokumen) tahap ini menggunakan rumus yaitu TF X IDF. Seperti pada proses ketiga yaitu VSM sama-sama mencari frekuenci kata yang muncul maka untuk proses ini tinggal mencari IDF nya kemudian di gunakan rumus TF-IDF nya.</p>
<p>Jika TF digunakan untuk mencari banyak kata yang muncul pada satu dokumen maka IDF digunakan untuk mengetahui dokumen yang mana saja yang memiliki kata kata yang sama.</p>
<p>Berikut codenya :</p>
<pre><code>df = list()
for d in range (len(matrix2[0])):
    total = 0
    for i in range(len(matrix2)):
        if matrix2[i][d] !=0:
            total += 1
    df.append(total)

idf = list()
for i in df:
    tmp = 1 + log10(len(matrix2)/(1+i))
    idf.append(tmp)

tf = matrix2
tfidf = []
for baris in range(len(matrix2)):
    tampungBaris = []
    for kolom in range(len(matrix2[0])):
        tmp = tf[baris][kolom] * idf[kolom]
        tampungBaris.append(tmp)
    tfidf.append(tampungBaris)
print(&quot;satu&quot;)

write_csv(&quot;tfidf_11_16.csv&quot;, tfidf)
</code></pre>

<p>Hasil TF-IDF disimpan dalam file csv tfidf_11_16.csv</p>
<h4 id="seleksi-fitur">SELEKSI FITUR</h4>
<p>untuk mengurangi fitur / kata yang sangat banyak karena tidak semua kata sangat dibutuhkan oleh karena itu perlu dilakukan pengurangan fitur tanpa mengurangi kualitas hasil akhirnya yaitu dengan seleksi fitur. Dan pada tahap seleksi fitur ini metode yang digunakan dengan Pearson Correlation yaitu, setiap fitur akan dihitung korelasinya kemudian jika terdapat fitur yang nilainya hampir sama tingginya maka akan dibuang salah satunya.</p>
<p>Berikut code programnya :</p>
<pre><code>   def pearsonCalculate(data, u,v):
       &quot;i, j is an index&quot;
       atas=0; bawah_kiri=0; bawah_kanan = 0
       for k in range(len(data)):
           atas += (data[k,u] - meanFitur[u]) * (data[k,v] - meanFitur[v])
           bawah_kiri += (data[k,u] - meanFitur[u])**2
           bawah_kanan += (data[k,v] - meanFitur[v])**2
       bawah_kiri = bawah_kiri ** 0.5
       bawah_kanan = bawah_kanan ** 0.5
       return atas/(bawah_kiri * bawah_kanan)
   def meanF(data):
       meanFitur=[]
       for i in range(len(data[0])):
           meanFitur.append(sum(data[:,i])/len(data))
       return np.array(meanFitur)
   def seleksiFiturPearson(data, threshold, berhasil):
       global meanFitur
       data = np.array(data)
       meanFitur = meanF(data)
       u=0
       while u &lt; len(data[0]):
           dataBaru=data[:, :u+1]
           meanBaru=meanFitur[:u+1]
           seleksikata=berhasil[:u+1]
           v = u
           while v &lt; len(data[0]):
               if u != v:
                   value = pearsonCalculate(data, u,v)
                   if value &lt; threshold:
                       dataBaru = np.hstack((dataBaru, data[:, v].reshape(data.shape[0],1)))
                       meanBaru = np.hstack((meanBaru, meanFitur[v]))
                       seleksikata = np.hstack((seleksikata, berhasil[v]))
               v+=1
           data = dataBaru
           meanFitur=meanBaru
           berhasil=seleksikata
           if u%50 == 0 : print(&quot;proses : &quot;, u, data.shape)
           u+=1
       return data, seleksikata
</code></pre>

<pre><code>   write_csv(&quot;kata_baru_11_16.csv&quot;, kataBaru2)
</code></pre>

<p>Kemudian hasil seleksi fitur disimpan kedalam file csv kata_baru_11_16.csv</p>
<h4 id="clustering">CLUSTERING</h4>
<p>mengelompokkan kata berdasarkan ciri yang mirip dan pada program ini dapat dilihat dari ciri kata yang digunakan pada suatu dokumen atau artikel. Untuk clustering kali ini digunakan metode C-Means Fuzzy.</p>
<pre><code>   cntr, u, u0, distant, fObj, iterasi, fpc =  fuzz.cmeans(xBaru1.T, 3, 2, 0.00001, 1000, seed=0)
   membership = np.argmax(u, axis=0)
</code></pre>

<p>code diatas adalah untuk clustering dengan C-Means Fuzzy dengan menggunakan  data, jumlah cluster, bobot(pangkat m), batas error max, dan max iterasi.</p>
<p>Setelah dilakukan clustering maka harus dicari nilai koefisien silhouette nya untuk melihat apakah hasilnya sudah bagus atau tidak. Nilai silhouette terletak antara -1 sampai 1 , hasil yang bagus adalah mendekati 1.</p>
<pre><code>   silhouette = silhouette_samples(xBaru1, membership)
   s_avg = silhouette_score(xBaru1, membership, random_state=10)
</code></pre>

<h4 id="kesimpulan">KESIMPULAN</h4>
<p>Dengan menggunakan seleksi fitur <em>Pearson Correlation Coefficient (PCC)</em> dan clustering dengan menggunakan <em>Fuzzy C-Means</em> hasil yang didapat mungkin masih kurang akurat karena percobaan yan dilakukan untuk membandingkannya tidaklah banyak</p>
<p>Untuk hasil data yang telah di crawling dapat dilihat melalui link github berikut :</p>
<p><a href="https://github.com/friskafatma/Web-Mining---Crawling">https://github.com/friskafatma/Web-Mining---Crawling</a></p>
<p><strong>Note : website yang sudah saya crawling datanya telah mengalami perubahan pada tampilan websitenya yaitu html dan css nya ketika saya menuliskan tutorial ini tepatnya tgl 20 April 2019, data yang saya tutorialkan adalah data yang lama karena lebih banyak artikel yang diunggah</strong></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
        
          <a href="webstruc/" title="Crawling Website Structure" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Crawling Website Structure
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="assets/javascripts/application.b806dc00.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"."}})</script>
      
    
  </body>
</html>